# 3D CNN for Alzheimerâ€™s Classification

_Reproducing Hao et al. (2019), â€œCNN Design for Alzheimerâ€™s Diseaseâ€_  
**Paper**: https://arxiv.org/pdf/1911.03740  
**Original code**: https://github.com/NYUMedML/CNN_design_for_AD

---

## ğŸ“š References

- **Target paper**: arXiv:1911.03740  
- **Original implementation**: NYUMedML/CNN_design_for_AD  

---

## ğŸ—‚ï¸ Data

We originally explored raw ADNIâ†’CLINICA preprocessing but ultimately used pre-processed volumes:
```bash
data/
â”œâ”€â”€ nifti/ # pre-processed .nii / .nii.gz files
â””â”€â”€ labels.tsv # subject_id, session, diagnosis, age
```
---

## ğŸ”§ Installation

```bash
conda create -n adni-cnn python=3.9 nibabel pytorch torchvision cudatoolkit=11.8 scikit-learn pyyaml tensorboard
conda activate adni-cnn
pip install pyhealth
```

---

## ğŸš€ Usage
1. Prepare data
Place your .nii / .nii.gz files under data/nifti/ and create data/labels.tsv.

2. Train the baseline model

```bash
python -m src.train
```
- Normalizes and augments (flips, rotations, translations)

- Trains 3-block 3D CNN (InstanceNorm)

- Logs metrics & graphs to TensorBoard

- Saves best weights to checkpoints/

3. Evaluate
At the end of training, the best model is automatically evaluated on the hold-out test split.

4. PyHealth variant

```bash
python -m src.train_pyhealth
```
Wraps our model for PyHealthâ€™s Trainer API.

---

## ğŸ§ª Ablation & Extensions
Toggle flags or edit code to explore:

- Normalization: InstanceNorm vs. BatchNorm

- Spatial downsampling: impact of early pooling

- Width vs. Depth: scaling filters vs. layers

- Age-incorporation: set include_age: true/false

---

## ğŸ“ˆ Results
After reproducing the baseline, we ran ablations:

1. Normalization: InstanceNorm â‰ˆ 2 % higher balanced accuracy than BatchNorm

2. Downsampling: Early aggressive pooling degrades performance by â‰ˆ 5 %

3. Width vs. Depth: Doubling width yields â‰ˆ 3 % gain; doubling depth shows diminishing returns

4. Age metadata: modest â‰ˆ 1.5 % performance boost

---

## ğŸ‘¤ Acknowledgements
Hao et al. (2019) for the original architecture & augmentations

ADNI consortium for the data

PyHealth for training utilities

